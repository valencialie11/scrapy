# Webscraping + Webcrawling using Scrapy

## Dependencies
- scrapy

Previously, I tried webscraping using beautifulsoup4 and so when I came across scrapy that enables you to webcrawl, I was beyond excited. I learnt this very simple webscraping and webcrawling exercise through https://www.digitalocean.com/community/tutorials/how-to-crawl-a-web-page-with-scrapy-and-python-3, so do check that comprehensive website out!
I then tried to apply what I learn from that website and modify it to suit my own needs and since I enjoy reading YA books, I figured that the best website to crawl is Goodreads. Weirdly, I found scrapy easier to use than beautifulsoup4 though I had to learn a bit about CSS and Xpath.
It is a very simple yet rewarding project and hopefully I get to expand this into something bigger?

- To run goodreadsbot.py into a csv (csv will be saved automatically under the name goodreads.csv in the same folder):

 ``` scrapy crawl goodreadsbot```

- To run it just in terminal of scraper.py:
     
```scrapy runspider scraper.py```

See you ~
